# -*- coding: utf-8 -*-
"""Sai_Pranathi_Employees_Burnout_Analysis_and_Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QvmYCw_mK_UH-ghLwQhINDaRoN9KgJ5p

# Employee Burnout Prediction


Employee burnout is a state of physical, emotional and mental exhaustion caused by excessive and prolonged stress. It can have serious consequences on an individual's well-being and can lead to decreased productivity and job performance. In today's fast-paced and constantly connected world, it is increasingly important to recognize and address the signs of burnout in order to maintain the health and well-being of employees.

 we will be exploring the use of regression techniques to predict employee burnout. By analyzing a dataset containing various factors that may contribute to burnout such as workload, mental fatigue job and work-life balance, we can develop a model to identify individuals who may be at risk of burnout. By proactively addressing these risk factors, organizations can help prevent burnout and promote the well-being of their employees.

## Dataset: Are Your Employees Burning Out?
This dataset consists of 9 columns as follows:

* **Employee ID**: The unique ID allocated for each employee **(example: fffe390032003000)**
* **Date of Joining**: The date-time when the employee has joined the organization **(example: 2008-12-30)**
* **Gender**: The gender of the employee **(Male/Female)**
* **Company Type**: The type of company where the employee is working **(Service/Product)**
* **WFH Setup Available**: Is the work from home facility available for the employee **(Yes/No)**
* **Designation**: The designation of the employee of work in the organization.
In the **range of [0.0, 5.0]** bigger is higher designation.
* **Resource Allocation**: The amount of resource allocated to the employee to work, ie. number of working hours.
In the **range of [1.0, 10.0]** (higher means more resource)
* **Mental Fatigue Score**: The level of fatigue mentally the employee is facing.
In the **range of [0.0, 10.0]** where 0.0 means no fatigue and 10.0 means completely fatigue.
* **Burn Rate**: The value we need to predict for each employee telling the rate of Bur out while working.
In the **range of [0.0, 1.0]** where the higher the value is more is the burn out.

## IMPORTING NECESSARY LIBRARIES
"""

# Importing neccesary liabries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import pickle as pickle
import os

"""## LOADING DATASET"""

data= pd.read_excel("employee_burnout_analysis-AI.xlsx")

"""## DATA OVERVIEW"""

data.head()

data.tail()

data.describe()

data.columns.tolist()

data.nunique()

data.info()

data.isnull().sum()

data.isnull().sum().values.sum()

"""## Exploratory Data Analysis

There are NaN values on our target ("Burn Rate") and also in Resource Allocation and Mental Fatigue Score columns. As we are going to perform supervised linear regression, our target variable is needed to do so. Therefore, this 1124 rows with NaN values must be dropped off of our dataframe.
"""

data.corr(numeric_only=True)['Burn Rate'][:-1]

"""These two variables are strongly correlated with target variable, therefore , important to estimate it."""

sns.pairplot(data)
plt.show()

"""Drop off all observations with NaN values of our dataframe."""

data = data.dropna()

data.shape

"""Analyzing what type of data is each variable."""

data.dtypes

"""The values that each variable contains.

The employees ID doesn't provide any useful information and, therefore, they must be dropped.
"""

data = data.drop('Employee ID', axis = 1)

"""# Outlier Detection"""

#visualation of outlier detection for Designation
plt.boxplot(data['Designation'])  #numerical values
plt.show()

#visualation of outlier detection for Resource Allocation
plt.boxplot(data['Resource Allocation'])    #numerical values
plt.show()

#visualation of outlier detection for Mental Fatigue Score
plt.boxplot(data['Mental Fatigue Score'])    #numerical values
plt.show()

data=data[(data['Mental Fatigue Score']<=10)&(data['Mental Fatigue Score']>=1.5)]

plt.boxplot(data['Mental Fatigue Score'])
plt.show()

#visualation of outlier detection for burn rate
plt.boxplot(data['Burn Rate'])    #numerical values
plt.show()

data=data[(data['Burn Rate']<=0.9)&(data['Burn Rate']>=0.0)]

plt.boxplot(data['Burn Rate'])
plt.show()

"""Checking the correlation of Date of Joining with Target variable"""

print(f"Min date {data['Date of Joining'].min()}")
print(f"Max date {data['Date of Joining'].max()}")
data_month = data.copy()

data_month["Date of Joining"] = data_month['Date of Joining'].astype("datetime64[ns]")  # Specify time unit as nanoseconds
data_month["Date of Joining"].groupby(data_month['Date of Joining'].dt.month).count().plot(kind="bar", xlabel='Month', ylabel="Hired employees")

""" The date of joining is uniform distributed with values between 2008-01-01 and 2008-12-31. So in order to create a new feature which represents the labor seniority, we could create a variable with the days worked"""

data_2008 = pd.to_datetime(["2008-01-01"]*len(data))
# Specify time unit as nanoseconds when converting to datetime64
data["Days"] = data['Date of Joining'].astype("datetime64[ns]").sub(data_2008).dt.days
data.Days

# Select only numeric columns before calculating correlation
numeric_data = data.select_dtypes(include=['number'])
correlation = numeric_data.corr()['Burn Rate']
print(correlation)

data.corr(numeric_only=True)['Burn Rate'][:]

"""We observed that there is no strong correlation between Date of Joining and Burn Rate.So, we are dropping the column Date of Joining."""

data = data.drop(['Date of Joining','Days'], axis = 1)

data.head()

"""Now  analysing the categorical variables"""

cat_columns = data.select_dtypes(object).columns
fig, ax = plt.subplots(nrows=1, ncols=len(cat_columns), sharey=True, figsize=(10, 5))
for i, c in enumerate(cat_columns):
    sns.countplot(x=c, data=data, ax=ax[i])
plt.show()

"""The number of observations of each category on each variable is equally distributed, except to the Company_Type where the number of service jobs its almost twice that of product ones.

# One-Hot Encoding for categorical features
"""

# Check if the columns exist before applying get_dummies
if all(col in data.columns for col in ['Company Type', 'WFH Setup Available', 'Gender']):
    data = pd.get_dummies(data, columns=['Company Type', 'WFH Setup Available','Gender'], drop_first=True)
    data.head()
    encoded_columns = data.columns
else:
    print("Error: One or more of the specified columns are not present in the DataFrame.")
    # Add debugging steps here to investigate why the columns are missing.
    # For example, print the existing columns:
    print(data.columns)

"""# Preprocessing"""

# Split df into X and y
y = data['Burn Rate']
X = data.drop('Burn Rate', axis=1)

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, shuffle=True, random_state=1)

# Scale X
scaler = StandardScaler()
scaler.fit(X_train)
X_train = pd.DataFrame(scaler.transform(X_train), index=X_train.index, columns=X_train.columns)
X_test = pd.DataFrame(scaler.transform(X_test), index=X_test.index, columns=X_test.columns )

X_train

y_train

"""# Model Building

## Decision Tree
"""

from sklearn.tree import DecisionTreeRegressor
model = DecisionTreeRegressor(random_state=42)

# Train the model
model.fit(X_train, y_train)

# Make predictions
y_pred = model.predict(X_test)

# Calculate evaluation metrics
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
mae = mean_absolute_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

# Print the results
print(f'Mean Squared Error (MSE): {mse}')
print(f'Root Mean Squared Error (RMSE): {rmse}')
print(f'Mean Absolute Error (MAE): {mae}')
print(f'R-squared (RÂ²): {r2}')

"""## Linear Regression"""

#from sklearn.linear_model import LinearRegression

# Create an instance of the LinearRegression class
linear_regression_model = LinearRegression()

# Train the model
linear_regression_model.fit(X_train, y_train)

#Linear Regressing Model Performance Metrics

print("Linear Regression Model Performance Metrics:\n")
# Make predictions on the test set
y_pred = linear_regression_model.predict(X_test)

# Calculate mean squared error
mse = mean_squared_error(y_test, y_pred)
print("Mean Squared Error:", mse)

# Calculate root mean squared error
rmse = mean_squared_error(y_test, y_pred, squared=False)
print("Root Mean Squared Error:", rmse)

# Calculate mean absolute error
mae = mean_absolute_error(y_test, y_pred)
print("Mean Absolute Error:", mae)

# Calculate R-squared score
r2 = r2_score(y_test, y_pred)
print("R-squared Score:", r2)

"""Based on the evaluation metrics, the Linear Regression model appears to be the best model for predicting burnout analysis.

It has the lowest mean squared error, root mean squared error, and mean absolute error, indicating better accuracy and precision in its predictions. Additionally, it has the highest R-squared score, indicating a good fit to the data and explaining a higher proportion of the variance in the target variable.

So we are choosing this model for deployment.
"""